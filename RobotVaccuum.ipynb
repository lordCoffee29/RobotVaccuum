{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEAS description of the cleaning phase\n",
    "\n",
    "__Performance Measure:__ Each action costs 1 energy unit. The performance is measured as the sum of the energy units used to clean the whole room.\n",
    "\n",
    "__Environment:__ A room with $n \\times n$ squares where $n = 5$. Dirt is randomly placed on each square with probability $p = 0.2$. For simplicity, you can assume that the agent knows the size and the layout of the room (i.e., it knows $n$). To start, the agent is placed on a random square.\n",
    "\n",
    "__Actuators:__ The agent can clean the current square (action `suck`) or move to an adjacent square by going `north`, `east`, `south`, or `west`.\n",
    "\n",
    "__Sensors:__ Four bumper sensors, one for north, east, south, and west; a dirt sensor reporting dirt in the current square.  \n",
    "\n",
    "\n",
    "## The agent program for a simple randomized agent\n",
    "\n",
    "The agent program is a function that gets sensor information (the current percepts) as the arguments. The arguments are:\n",
    "\n",
    "* A dictionary with boolean entries for the for bumper sensors `north`, `east`, `west`, `south`. E.g., if the agent is on the north-west corner, `bumpers` will be `{\"north\" : True, \"east\" : False, \"south\" : False, \"west\" : True}`.\n",
    "* The dirt sensor produces a boolean.\n",
    "\n",
    "The agent returns the chosen action as a string.\n",
    "\n",
    "Here is an example implementation for the agent program of a simple randomized agent:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "actions = [\"north\", \"east\", \"west\", \"south\", \"suck\"]\n",
    "\n",
    "def simple_randomized_agent(bumpers, dirty):\n",
    "    return np.random.choice(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'north'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define percepts (current location is NW corner and it is dirty)\n",
    "bumpers = {\"north\" : True, \"east\" : False, \"south\" : False, \"west\" : True}\n",
    "dirty = True\n",
    "\n",
    "# call agent program function with percepts and it returns an action\n",
    "simple_randomized_agent(bumpers, dirty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This is not a rational intelligent agent. It ignores its sensors and may bump into a wall repeatedly or not clean a dirty square. You will be asked to implement rational agents below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple environment example\n",
    "\n",
    "We implement a simple simulation environment that supplies the agent with its percepts.\n",
    "The simple environment is infinite in size (bumpers are always `False`) and every square is always dirty, even if the agent cleans it. The environment function returns a different performance measure than the one specified in the PEAS description! Since the room is infinite and all squares are constantly dirty, the agent can never clean the whole room. Your implementation needs to implement the **correct performance measure.** The energy budget of the agent is specified as `max_steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_environment(agent, n, max_steps, verbose = True):\n",
    "    num_cleaned = 0\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        dirty = True\n",
    "        bumpers = {\"north\" : False, \"south\" : False, \"west\" : False, \"east\" : False}\n",
    "\n",
    "        action = agent(bumpers, dirty)\n",
    "        if (verbose): print(\"step\", i , \"- action:\", action)\n",
    "\n",
    "        if (action == \"suck\"):\n",
    "            num_cleaned = num_cleaned + 1\n",
    "\n",
    "    return num_cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do one simulation run with a simple randomized agent that has enough energy for 20 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 - action: west\n",
      "step 1 - action: west\n",
      "step 2 - action: west\n",
      "step 3 - action: suck\n",
      "step 4 - action: north\n",
      "step 5 - action: suck\n",
      "step 6 - action: east\n",
      "step 7 - action: east\n",
      "step 8 - action: west\n",
      "step 9 - action: suck\n",
      "step 10 - action: suck\n",
      "step 11 - action: east\n",
      "step 12 - action: suck\n",
      "step 13 - action: west\n",
      "step 14 - action: suck\n",
      "step 15 - action: west\n",
      "step 16 - action: north\n",
      "step 17 - action: south\n",
      "step 18 - action: suck\n",
      "step 19 - action: south\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_environment(simple_randomized_agent, n = 5, max_steps = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement a simulation environment\n",
    "\n",
    "The simple environment above is not very realistic. This environment simulator needs to:\n",
    "\n",
    "* Initialize the environment by storing the state of each square (clean/dirty) and making some dirty.\n",
    "* Keep track of the agent's position.\n",
    "* Call the agent function repeatedly and provide the agent function with the sensor inputs.  \n",
    "* React to the agent's actions. E.g, by removing dirt from a square or moving the agent around unless there is a wall in the way.\n",
    "* Keep track of the performance measure. That is, track the agent's actions until all dirty squares are clean and count the number of actions it takes the agent to complete the task.\n",
    "\n",
    "The implementation holds a 2-dimensional array to represent if squares are clean or dirty and to call the agent function in a loop until all squares are clean or a predefined number of steps have been reached (i.e., the robot runs out of energy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on implementation:\n",
    "\n",
    "My approach on this task began with an agent that reacts only to dirt.  If the square is dirty, the robot will clean it.  If not, the robot will randomly attempt to move to another square.\n",
    "\n",
    "The testing environment is a 5x5 grid with 1's and 0's.  A 1 means the square is dirty. A 0 means the square is clean.  There is a 20% chance each square will be dirty.  The robot will continue until either all dirty squares are clean or until it's out of energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "actions = [\"north\", \"east\", \"west\", \"south\"]\n",
    "\n",
    "# This randomized agent reacts to dirt; cleans if dirty, moves if not\n",
    "def randomized_agent(bumpers, dirty):\n",
    "  if(dirty):\n",
    "    return \"suck\"\n",
    "  else:\n",
    "    return np.random.choice(actions)\n",
    "\n",
    "def simulation_environment(agent, n, max_steps, verbose = True):\n",
    "\n",
    "  # Creating the environment/starting parameters\n",
    "  rng = np.random.default_rng()\n",
    "  p = .2\n",
    "  values = []\n",
    "  steps = 0\n",
    "  cleaned = 0\n",
    "\n",
    "  # Generate the environment of clean and dirty squares\n",
    "  for i in range(n*n):\n",
    "    values.append(rng.random() < p)\n",
    "\n",
    "  env = np.array(values).reshape(n, n)\n",
    "  env = 1*env\n",
    "\n",
    "  # Count of dirty squares in the environment\n",
    "  dirty_count = env.sum()\n",
    "\n",
    "  # The robot spawns into the environment\n",
    "  pos = [np.random.randint(0, n - 1), np.random.randint(0, n - 1)]\n",
    "\n",
    "\n",
    "  # The robot begins cleaning the environment\n",
    "  while(steps < max_steps and cleaned < dirty_count):\n",
    "      # Get the location into x and y coordinates\n",
    "      x, y = pos\n",
    "      # If the square is dirty or not\n",
    "      dirty = env[x, y]\n",
    "\n",
    "      # Bumper sensor to pass into the agent (not considered for this task)\n",
    "      bumpers = {\"north\" : x == 0, \"south\" : x == n - 1, \"west\" : y == 0, \"east\" : y == n - 1}\n",
    "\n",
    "      # Call agent function to react to the dirt sensor and the bumper sensor\n",
    "      action = agent(bumpers, dirty)\n",
    "\n",
    "      # Step 1\n",
    "      if (verbose): print(\"step\", steps + 1, \": position:\", pos, \"action: \", action)\n",
    "\n",
    "      # Update the location and/or cleanliness status of the square based on the action\n",
    "      if (action == \"suck\"):\n",
    "        cleaned += 1\n",
    "        env[pos] = False\n",
    "      elif(action == \"north\" and bumpers[\"north\"] == False):\n",
    "        pos[0] -= 1\n",
    "      elif(action == \"east\" and bumpers[\"east\"] == False):\n",
    "        pos[1] += 1\n",
    "      elif(action == \"west\" and bumpers[\"west\"] == False):\n",
    "        pos[1] -= 1\n",
    "      elif(action == \"south\" and bumpers[\"south\"] == False):\n",
    "        pos[0] += 1\n",
    "\n",
    "      # Move onto the next step\n",
    "      steps += 1\n",
    "\n",
    "  return cleaned, steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 : position: [3, 2] action:  suck\n",
      "step 2 : position: [3, 2] action:  east\n",
      "step 3 : position: [3, 3] action:  south\n",
      "step 4 : position: [4, 3] action:  west\n",
      "step 5 : position: [4, 2] action:  east\n",
      "step 6 : position: [4, 3] action:  east\n",
      "step 7 : position: [4, 4] action:  north\n",
      "step 8 : position: [3, 4] action:  east\n",
      "step 9 : position: [3, 4] action:  east\n",
      "step 10 : position: [3, 4] action:  north\n",
      "step 11 : position: [2, 4] action:  west\n",
      "step 12 : position: [2, 3] action:  north\n",
      "step 13 : position: [1, 3] action:  west\n",
      "step 14 : position: [1, 2] action:  east\n",
      "step 15 : position: [1, 3] action:  south\n",
      "step 16 : position: [2, 3] action:  south\n",
      "step 17 : position: [3, 3] action:  north\n",
      "step 18 : position: [2, 3] action:  east\n",
      "step 19 : position: [2, 4] action:  south\n",
      "step 20 : position: [3, 4] action:  north\n",
      "Finished: Energy used (performance measure): 20\n",
      "Total cleaned: 1, Steps taken: 20\n"
     ]
    }
   ],
   "source": [
    "# Run the agent in the environment\n",
    "cleaned, steps = simulation_environment(randomized_agent, n = 5, max_steps = 20)\n",
    "print(f\"Finished: Energy used (performance measure): {steps}\\nTotal cleaned: {cleaned}, Steps taken: {steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2:  Implement a simple reflex agent\n",
    "\n",
    "The simple reflex agent randomly walks around but reacts to the bumper sensor by not bumping into the wall and to dirt with sucking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on implementation:\n",
    "\n",
    "My approach on this task began with an agent that reacts only to dirt.  If the square is dirty, the robot will clean it.  If not, the robot will randomly attempt to move to another square.  This time, the robot will not proceed if it is blocked by one of the walls.  It does this by randomly generating an action, but if the bumper sensor is activated, it will generate another action.  Only an action that isn't blocked will be returned to the environment.\n",
    "\n",
    "This task uses the same environment from the last task.  The testing environment is a 5x5 grid with 1's and 0's.  A 1 means the square is dirty. A 0 means the square is clean.  There is a 20% chance each square will be dirty.  The robot will continue until either all dirty squares are clean or until it's out of energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Possible actions\n",
    "actions = [\"north\", \"east\", \"west\", \"south\"]\n",
    "\n",
    "# Creating the simple reflex agent\n",
    "#    This agent reacs to bumper sensors, unlike the other one\n",
    "def simple_reflex_agent(bumpers, dirty):\n",
    "  if(dirty):\n",
    "    return \"suck\"\n",
    "  else:\n",
    "    while(True):\n",
    "      # Randomly generates an action and checks to see if it's blocked\n",
    "      action = np.random.choice(actions)\n",
    "      # Proceed if not blocked\n",
    "      if(bumpers[action] == False):\n",
    "          return action\n",
    "          break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 : position: [0, 3] action:  south\n",
      "step 2 : position: [1, 3] action:  east\n",
      "step 3 : position: [1, 4] action:  north\n",
      "step 4 : position: [0, 4] action:  south\n",
      "step 5 : position: [1, 4] action:  south\n",
      "step 6 : position: [2, 4] action:  west\n",
      "step 7 : position: [2, 3] action:  east\n",
      "step 8 : position: [2, 4] action:  south\n",
      "step 9 : position: [3, 4] action:  west\n",
      "step 10 : position: [3, 3] action:  south\n",
      "step 11 : position: [4, 3] action:  west\n",
      "step 12 : position: [4, 2] action:  east\n",
      "step 13 : position: [4, 3] action:  north\n",
      "step 14 : position: [3, 3] action:  south\n",
      "step 15 : position: [4, 3] action:  east\n",
      "step 16 : position: [4, 4] action:  west\n",
      "step 17 : position: [4, 3] action:  west\n",
      "step 18 : position: [4, 2] action:  north\n",
      "step 19 : position: [3, 2] action:  suck\n",
      "step 20 : position: [3, 2] action:  north\n",
      "Finished: Energy used (performance measure): 20\n",
      "Total cleaned: 1, Steps taken: 20\n"
     ]
    }
   ],
   "source": [
    "# Run the agent in the environment\n",
    "cleaned, steps = simulation_environment(simple_reflex_agent, n = 5, max_steps = 20)\n",
    "print(f\"Finished: Energy used (performance measure): {steps}\\nTotal cleaned: {cleaned}, Steps taken: {steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Implement a model-based reflex agent\n",
    "\n",
    "Model-based agents use a state to keep track of what they have done and perceived so far. This agent needs to find out where it is located and then keep track of its current location. There also needs to be a set of rules based on the state and the percepts to make sure that the agent will clean the whole room. For example, the agent can move to a corner to determine its location and then it can navigate through the whole room and clean dirty squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on implementation:\n",
    "\n",
    "My approach on this task begins with creating an Agent class.  The class keeps track of the robot's location, unlike previous agents.  It has two actions: go to the corner and the standard cleaning action.  The first action is going to the corner, where it's not cleaning anything but simply relocating to the northwest corner.  Then, the \"act\" is called, in which the robot goes from one side of the grid to the other to clean, moving down when it has completed a row.\n",
    "\n",
    "The environment is slightly modified, as the robot keeps track of its location.  The environment includes a start where the robot finds the corner, and then begins cleaning.  What's different is that the location is updated and stored within the robot instead of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model-based agent\n",
    "class Agent:\n",
    "    def __init__(self, pos = [0, 0], name = \"Agent\"):\n",
    "        # Initialization parameters\n",
    "        self.pos = pos\n",
    "        self.x = pos[0]\n",
    "        self.y = pos[1]\n",
    "        self.name = name\n",
    "\n",
    "    # Updates the location, the robot keeps track\n",
    "    def update_loc(self, action):\n",
    "        if(action == \"north\"):\n",
    "          self.x -= 1\n",
    "        elif(action == \"south\"):\n",
    "          self.x += 1\n",
    "        elif(action == \"west\"):\n",
    "          self.y -= 1\n",
    "        elif(action == \"east\"):\n",
    "          self.y += 1\n",
    "\n",
    "    # Return the location of the robot\n",
    "    def get_loc(self):\n",
    "        return [self.x, self.y]\n",
    "\n",
    "    # Return the x-coordinate of the robot\n",
    "    def get_loc_x(self):\n",
    "        return self.x\n",
    "\n",
    "    # Return the y-coordinate of the robot\n",
    "    def get_loc_y(self):\n",
    "        return self.y\n",
    "\n",
    "    # The robot finds the northwest corner\n",
    "    def go_to_corner(self, go_here):\n",
    "        action = go_here\n",
    "\n",
    "        if(go_here == \"north\" and self.x > 0):\n",
    "          self.pos = [self.x - 1, self.y]\n",
    "        elif(go_here == \"west\" and self.y > 0):\n",
    "          self.pos = ([self.x, self.y - 1])\n",
    "\n",
    "        return action\n",
    "\n",
    "    # Cleans the room from the corner\n",
    "    def act(self, bumpers, dirty):\n",
    "        if(dirty):\n",
    "          return \"suck\"\n",
    "        # If on an even row (0, 2, 4...), the robot will move east and then move\n",
    "        #    south if the wall is encountered\n",
    "        elif(self.x % 2 == 0):\n",
    "          if(bumpers[\"east\"] == True):\n",
    "            return \"south\"\n",
    "          else:\n",
    "            return \"east\"\n",
    "        # If on an odd row (1, 3, 5...), the robot will move west and then move\n",
    "        #    south if the wall is encountered\n",
    "        elif(self.x % 2 == 1):\n",
    "          if(bumpers[\"west\"] == True):\n",
    "            return \"south\"\n",
    "          else:\n",
    "            return \"west\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an environment for the model-based reflex agent\n",
    "def new_environment(agent, n, max_steps, verbose = True):\n",
    "\n",
    "  # Creating the environment/starting parameters\n",
    "  rng = np.random.default_rng()\n",
    "  p = .2\n",
    "  values = []\n",
    "  steps = 0\n",
    "  cleaned = 0\n",
    "\n",
    "  # Create the environment of clean and dirty squares\n",
    "  for i in range(n*n):\n",
    "    values.append(rng.random() < p)\n",
    "\n",
    "  env = np.array(values).reshape(n, n)\n",
    "  env = 1*env\n",
    "\n",
    "  # Count of all dirty squares in the environment\n",
    "  dirty_count = env.sum()\n",
    "\n",
    "  # Finding the x-coordinate of the northwest corner\n",
    "  while(agent.get_loc_x() != 0):\n",
    "    action = agent.go_to_corner(\"north\")\n",
    "    if (verbose): print(\"step\", steps + 1, \": position:\", agent.get_loc(), \"action: \", action)\n",
    "    agent.update_loc(action)\n",
    "    steps += 1\n",
    "\n",
    "  # Finding the y-coordinate of the northwest corner\n",
    "  while(agent.get_loc_y() != 0):\n",
    "    action = agent.go_to_corner(\"west\")\n",
    "    if (verbose): print(\"step\", steps + 1, \": position:\", agent.get_loc(), \"action: \", action)\n",
    "    agent.update_loc(action)\n",
    "    steps += 1\n",
    "\n",
    "  # Cleaning the environment\n",
    "  while(steps < max_steps and cleaned < dirty_count):\n",
    "      # Get the x and y coordinates of the robot's location\n",
    "      x = agent.get_loc_x()\n",
    "      y = agent.get_loc_y()\n",
    "\n",
    "      # If a square is dirty or not\n",
    "      dirty = env[x, y]\n",
    "\n",
    "      # Bumper information\n",
    "      bumpers = {\"north\" : x == 0, \"south\" : x == n - 1, \"west\" : y == 0, \"east\" : y == n - 1}\n",
    "\n",
    "      # Generate an action based on the bumper and dirt sensor\n",
    "      action = agent.act(bumpers, dirty)\n",
    "\n",
    "      # Step 1\n",
    "      if (verbose): print(\"step\", steps + 1, \": position:\", agent.get_loc(), \"action: \", action)\n",
    "\n",
    "      # Robot either cleans or moves\n",
    "      if(action == \"suck\"):\n",
    "        cleaned += 1\n",
    "        env[tuple(agent.get_loc())] = 0\n",
    "      else:\n",
    "        agent.update_loc(action)\n",
    "\n",
    "      # Move to next step\n",
    "      steps += 1\n",
    "\n",
    "  return cleaned, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 : position: [3, 3] action:  north\n",
      "step 2 : position: [2, 3] action:  north\n",
      "step 3 : position: [1, 3] action:  north\n",
      "step 4 : position: [0, 3] action:  west\n",
      "step 5 : position: [0, 2] action:  west\n",
      "step 6 : position: [0, 1] action:  west\n",
      "step 7 : position: [0, 0] action:  suck\n",
      "step 8 : position: [0, 0] action:  east\n",
      "step 9 : position: [0, 1] action:  east\n",
      "step 10 : position: [0, 2] action:  east\n",
      "step 11 : position: [0, 3] action:  east\n",
      "step 12 : position: [0, 4] action:  south\n",
      "step 13 : position: [1, 4] action:  west\n",
      "step 14 : position: [1, 3] action:  west\n",
      "step 15 : position: [1, 2] action:  west\n",
      "step 16 : position: [1, 1] action:  west\n",
      "step 17 : position: [1, 0] action:  south\n",
      "step 18 : position: [2, 0] action:  east\n",
      "step 19 : position: [2, 1] action:  east\n",
      "step 20 : position: [2, 2] action:  east\n",
      "step 21 : position: [2, 3] action:  east\n",
      "step 22 : position: [2, 4] action:  south\n",
      "step 23 : position: [3, 4] action:  west\n",
      "step 24 : position: [3, 3] action:  west\n",
      "step 25 : position: [3, 2] action:  west\n",
      "step 26 : position: [3, 1] action:  suck\n",
      "step 27 : position: [3, 1] action:  west\n",
      "step 28 : position: [3, 0] action:  suck\n",
      "Finished: Energy used (performance measure): 28\n",
      "Total cleaned: 3, Steps taken: 28\n"
     ]
    }
   ],
   "source": [
    "# Running the agent in the environment\n",
    "n = 5\n",
    "pos = [np.random.randint(0, n - 1), np.random.randint(0, n - 1)]\n",
    "agent = Agent(pos = pos, name = \"Agent\")\n",
    "cleaned, steps = new_environment(agent, n = 5, max_steps = 100)\n",
    "print(f\"Finished: Energy used (performance measure): {steps}\\nTotal cleaned: {cleaned}, Steps taken: {steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Simulation study [30 Points]\n",
    "\n",
    "Comparison of the performance (the performance measure is defined in the PEAS description above) of the agents using environments of different size. E.g., $5 \\times 5$, $10 \\times 10$ and\n",
    "$100 \\times 100$. Used 100 random runs for each and the results are presented using tables and graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists for all the performance scores\n",
    "ra_perf = []\n",
    "sra_perf = []\n",
    "mra_perf = []\n",
    "\n",
    "# Buffer\n",
    "temp = []\n",
    "\n",
    "# Reflex agent - 5x5\n",
    "for i in range(100):\n",
    "  cleaned, steps = simulation_environment(randomized_agent, n = 5, max_steps = 1000, verbose = False)\n",
    "  temp.append(steps)\n",
    "\n",
    "ra_perf.append(temp)\n",
    "temp = []\n",
    "\n",
    "# Reflex agent - 10x10\n",
    "for i in range(100):\n",
    "  cleaned, steps = simulation_environment(randomized_agent, n = 10, max_steps = 1000, verbose = False)\n",
    "  temp.append(steps)\n",
    "\n",
    "ra_perf.append(temp)\n",
    "temp = []\n",
    "\n",
    "# Reflex agent - 100x100\n",
    "for i in range(100):\n",
    "  cleaned, steps = simulation_environment(randomized_agent, n = 100, max_steps = 1000, verbose = False)\n",
    "  temp.append(steps)\n",
    "\n",
    "ra_perf.append(temp)\n",
    "temp = []\n",
    "\n",
    "\n",
    "# Simple reflex agent - 5x5\n",
    "for i in range(100):\n",
    "  cleaned, steps = simulation_environment(simple_reflex_agent, n = 5, max_steps = 1000, verbose = False)\n",
    "  temp.append(steps)\n",
    "\n",
    "sra_perf.append(temp)\n",
    "temp = []\n",
    "\n",
    "# Simple reflex agent - 10x10\n",
    "for i in range(100):\n",
    "  cleaned, steps = simulation_environment(simple_reflex_agent, n = 10, max_steps = 1000, verbose = False)\n",
    "  temp.append(steps)\n",
    "\n",
    "sra_perf.append(temp)\n",
    "temp = []\n",
    "\n",
    "# Simple reflex agent - 10x10\n",
    "for i in range(100):\n",
    "  cleaned, steps = simulation_environment(simple_reflex_agent, n = 100, max_steps = 1000, verbose = False)\n",
    "  temp.append(steps)\n",
    "\n",
    "sra_perf.append(temp)\n",
    "temp = []\n",
    "\n",
    "\n",
    "# Model-based reflex agent - 5x5\n",
    "for i in range(100):\n",
    "  n = 5\n",
    "  pos = [np.random.randint(0, n - 1), np.random.randint(0, n - 1)]\n",
    "  agent = Agent(pos = pos, name = \"Agent 5\")\n",
    "  cleaned, steps = new_environment(agent, n = n, max_steps = 1000, verbose = False)\n",
    "  temp.append(steps)\n",
    "\n",
    "mra_perf.append(temp)\n",
    "temp = []\n",
    "\n",
    "# Model-based reflex agent - 10x10\n",
    "for i in range(100):\n",
    "  n = 10\n",
    "  pos = [np.random.randint(0, n - 1), np.random.randint(0, n - 1)]\n",
    "  agent = Agent(pos = pos, name = \"Agent 5\")\n",
    "  cleaned, steps = new_environment(agent, n = n, max_steps = 1000, verbose = False)\n",
    "  temp.append(steps)\n",
    "\n",
    "mra_perf.append(temp)\n",
    "temp = []\n",
    "\n",
    "# Model-based reflex agent - 100x100\n",
    "for i in range(100):\n",
    "  n = 100\n",
    "  pos = [np.random.randint(0, n - 1), np.random.randint(0, n - 1)]\n",
    "  agent = Agent(pos = pos, name = \"Agent 5\")\n",
    "  cleaned, steps = new_environment(agent, n = n, max_steps = 1000, verbose = False)\n",
    "  temp.append(steps)\n",
    "\n",
    "mra_perf.append(temp)\n",
    "temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather each average\n",
    "average_ra_5 = np.mean(ra_perf[0])\n",
    "average_ra_10 = np.mean(ra_perf[1])\n",
    "average_ra_100 = np.mean(ra_perf[2])\n",
    "average_sra_5 = np.mean(sra_perf[0])\n",
    "average_sra_10 = np.mean(sra_perf[1])\n",
    "average_sra_100 = np.mean(sra_perf[2])\n",
    "average_mra_5 = np.mean(mra_perf[0])\n",
    "average_mra_10 = np.mean(mra_perf[1])\n",
    "average_mra_100 = np.mean(mra_perf[2])\n",
    "\n",
    "# Store the averages\n",
    "average_ra = [average_ra_5, average_ra_10, average_ra_100]\n",
    "average_sra = [average_sra_5, average_sra_10, average_sra_100]\n",
    "average_mra = [average_mra_5, average_mra_10, average_mra_100]\n",
    "\n",
    "# Cumulative averages\n",
    "averages = [average_ra, average_sra, average_mra]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the following table with the average performance measure for 100 random runs (you may also create this table with code):\n",
    "\n",
    "| Size     | Randomized Agent | Simple Reflex Agent | Model-based Reflex Agent |\n",
    "|----------|------------------|---------------------|--------------------------|\n",
    "| 5x5     |897.99|898.6|28.24 |\n",
    "| 10x10   |1000.0 |1000.0 |124.48 |\n",
    "| 100x100 |1000.0 |1000.0 |1000.0 |\n",
    "\n",
    "Add charts to compare the performance of the different agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aesthetic graph parameters\n",
    "N = 3\n",
    "ind = np.arange(N)\n",
    "width = 0.25\n",
    "\n",
    "# Set up each of the bars (an agent per bar)\n",
    "bar1 = plt.bar(ind, average_ra, width, color = 'lightblue')\n",
    "bar2 = plt.bar(ind+width, average_sra, width, color='mediumblue')\n",
    "bar3 = plt.bar(ind+width*2, average_mra, width, color = 'darkblue')\n",
    "\n",
    "# Graph labels\n",
    "plt.xlabel(\"Size\")\n",
    "plt.ylabel('Performance measure (average steps)')\n",
    "plt.title(\"Performance measure (average steps) of each Agent in Various Grid Sizes\")\n",
    "\n",
    "# Generate the graph\n",
    "plt.xticks(ind+width,['5 x 5', '10 x 10', '100 x 100'] )\n",
    "plt.legend((bar1, bar2, bar3), ('Randomized Agent', 'Simple Randomized Agent', 'Model-Based Randomized Agent'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "Overall, the randomized agent and the simple randomized agent performed relatively similarly.  This makes sense because both agents rely on pure randomization, even if one has a parameter that reduces some randomness.  The model-based random agent seemed to perform better, as it was certain that it would hit all the squares.  While the random agents might have circled all around the grid without checking all the squares.  However, for a 100x100, all models seemed to perform the same.  With a higher max_steps count, a difference might be more apparent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
